{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "from time import time\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from accelerate import PartialState\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, LlamaModel, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "from huggingface_hub import login\n",
    "tqdm.pandas()\n",
    "\n",
    "# Change the working directory to the directory containing the script\n",
    "os.chdir(\"/group-volume/binfeng/wsdm/stage_distill\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"Qwen/Qwen2.5-14B-Instruct\"\n",
    "MAX_LENGTH = 2000\n",
    "MAX_PROMPT_LENGTH = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/group-volume/binfeng/wsdm/tokenizer/qwen14b/tokenizer_config.json',\n",
       " '/group-volume/binfeng/wsdm/tokenizer/qwen14b/special_tokens_map.json',\n",
       " '/group-volume/binfeng/wsdm/tokenizer/qwen14b/vocab.json',\n",
       " '/group-volume/binfeng/wsdm/tokenizer/qwen14b/merges.txt',\n",
       " '/group-volume/binfeng/wsdm/tokenizer/qwen14b/added_tokens.json',\n",
       " '/group-volume/binfeng/wsdm/tokenizer/qwen14b/tokenizer.json')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'right'\n",
    "tokenizer.save_pretrained(\"/group-volume/binfeng/wsdm/tokenizer/qwen14b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47952 485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.11/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=100.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "ft = pd.read_parquet(\"/group-volume/binfeng/wsdm/stage_distill/datap/ft48k.parquet\")\n",
    "ft.dropna(inplace=True)\n",
    "ft[\"text\"] = ft.apply(lambda x: format_text(tokenizer, x.prompt, x.response_a, x.response_b, \n",
    "                                                max_len=MAX_LENGTH, max_prompt_len=MAX_PROMPT_LENGTH), axis=1)\n",
    "ft[\"label\"] = ft.apply(lambda x: format_label(x.winner), axis=1)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=100, shuffle=True, random_state=10)\n",
    "for train_index, val_index in skf.split(ft, ft[\"language\"]):\n",
    "    ft_train, ft_val = ft.iloc[train_index], ft.iloc[val_index]\n",
    "    print(len(ft_train), len(ft_val))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135588 136\n"
     ]
    }
   ],
   "source": [
    "ppt = pd.read_parquet(\"/group-volume/binfeng/wsdm/stage_distill/datap/ppt135k.parquet\")\n",
    "ppt.dropna(inplace=True)\n",
    "ppt[\"text\"] = ppt.apply(lambda x: format_text(tokenizer, x.prompt, x.response_a, x.response_b, \n",
    "                                                max_len=MAX_LENGTH, max_prompt_len=MAX_PROMPT_LENGTH), axis=1)\n",
    "ppt[\"label\"] = ppt.apply(lambda x: format_label(x.winner), axis=1)\n",
    "\n",
    "kf = KFold(n_splits=1000, shuffle=True, random_state=10)\n",
    "for train_index, val_index in kf.split(ppt):\n",
    "    ppt_train, ppt_val = ppt.iloc[train_index], ppt.iloc[val_index]\n",
    "    print(len(ppt_train), len(ppt_val))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 135588/135588 [01:34<00:00, 1432.87 examples/s]\n",
      "Map: 100%|██████████| 136/136 [00:00<00:00, 1472.10 examples/s]\n",
      "Map: 100%|██████████| 47952/47952 [00:35<00:00, 1339.44 examples/s]\n",
      "Map: 100%|██████████| 485/485 [00:00<00:00, 1358.12 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    ppt135k_train: Dataset({\n",
       "        features: ['labels', 'logits_qwencd', 'logits_qwen32', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 135588\n",
       "    })\n",
       "    ppt135k_val: Dataset({\n",
       "        features: ['labels', 'logits_qwencd', 'logits_qwen32', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 136\n",
       "    })\n",
       "    ft48k_train: Dataset({\n",
       "        features: ['labels', 'logits_qwencd', 'logits_qwen32', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 47952\n",
       "    })\n",
       "    ft48k_val: Dataset({\n",
       "        features: ['labels', 'logits_qwencd', 'logits_qwen32', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 485\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer_func(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"], \n",
    "        padding='max_length', \n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=True,\n",
    "        return_tensors='np'\n",
    "    )\n",
    "\n",
    "\n",
    "ppt_train_dataset = Dataset.from_pandas(ppt_train[[\"text\", \"label\", \"logits_qwencd\", \"logits_qwen32\"]])\n",
    "ppt_val_dataset = Dataset.from_pandas(ppt_val[[\"text\", \"label\", \"logits_qwencd\", \"logits_qwen32\"]])\n",
    "ft_train_dataset = Dataset.from_pandas(ft_train[[\"text\", \"label\", \"logits_qwencd\", \"logits_qwen32\"]])\n",
    "ft_val_dataset = Dataset.from_pandas(ft_val[[\"text\", \"label\", \"logits_qwencd\", \"logits_qwen32\"]])\n",
    "raw_dataset = DatasetDict({\n",
    "    'ppt135k_train': ppt_train_dataset,\n",
    "    'ppt135k_val': ppt_val_dataset,\n",
    "    'ft48k_train': ft_train_dataset,\n",
    "    'ft48k_val': ft_val_dataset,\n",
    "})\n",
    "\n",
    "tokenized_dataset = raw_dataset.map(tokenizer_func, batched=True)\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
    "tokenized_dataset = tokenized_dataset.remove_columns(['__index_level_0__', 'text'])\n",
    "tokenized_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.9086914, -1.5205078]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"ft48k_train\"][\"logits_qwen32\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|User Prompt|>\n",
      "I'm looking to self-host a fully integrated DB platform that supports the database, authentication (oauth) for customers of the system, and granular permissions with an API to access DB data. Can you compare platforms like Supabase, appwrite, budibase, directus, surrealDB, parse, couchbase, and any other suggestions. Particularly on how easy it is to self host and what feature parity self hosting has. Please note if the backend is something generic that could be easily migrated away from.\n",
      "\n",
      "scale: No huge amounts of data, just medium size catalogues of products for online stores.\n",
      "features: DO NOT need realtime or spatial, but full text search would be nice\n",
      "ease of use: Ideally something with a GUI or WebUI for graphical monitoring/management\n",
      "cost: free/open source is ideal. no concerns on hardware costs, that's already covered\n",
      "\n",
      "It should be able to host multiple sites and have customer oauth for each\n",
      "\n",
      "Put the comparison into a table\n",
      "\n",
      "<|Response A|>\n",
      "Certainly! Below is a comparison table for the platforms you've mentioned, as well as a few others that might fit your requirements. The comparison focuses on self-hosting ease, feature parity, and other relevant factors.\n",
      "\n",
      "| **Platform** | **Ease of Self-Hosting** | **Feature Parity (Self-Hosted vs. Cloud)** | **GUI/WebUI** | **Full Text Search** | **Customer OAuth** | **Granular Permissions** | **API Access** | **Multi-Site Support** | **Backend Flexibility** | **Cost (Open Source/Free)** |\n",
      "|--------------|--------------------------|--------------------------------------------|---------------|----------------------|--------------------|--------------------------|----------------|------------------------|-------------------------|------------------------------|\n",
      "| **Supabase** | Moderate                 | High                                       | Yes           | Yes                  | Yes                | Yes                      | Yes            | Limited (one instance per project) | PostgreSQL | Open Source (MIT License) |\n",
      "| **Appwrite** | Easy                     | High                                       | Yes           | No (but can be added via plugins) | Yes                | Yes                      | Yes            | Yes                    | Generic (can use multiple backends) | Open Source (Apache 2.0) |\n",
      "| **Budibase** | Easy                     | High                                       | Yes           | No (but can be added via plugins) | Yes                | Yes                      | Yes            | Yes                    | MongoDB, PostgreSQL, MySQL | Open Source (GPL-3.0) |\n",
      "| **Directus** | Easy                     | High                                       | Yes           | Yes (via extensions) | Yes                | Yes                      | Yes            | Yes                    | SQL-based (PostgreSQL, MySQL, SQLite, etc.) | Open Source (GPL-3.0) |\n",
      "| **SurrealDB** | Moderate                 | High                                       | No (CLI only) | Yes                  | No (but can be implemented) | No (but can be implemented) | Yes            | No (single instance)   | SurrealDB (proprietary) | Open Source (MIT License) |\n",
      "| **Parse**    | Easy                     | High                                       | Yes           | No (but can be added via plugins) | Yes                | Yes                      | Yes            | Yes                    | MongoDB, PostgreSQL, MySQL | Open Source (BSD-3-Clause) |\n",
      "| **Couchbase** | Moderate                 | High                                       | Yes           | No (but can be added via plugins) | Yes                | Yes                      | Yes            | Yes                    | Couchbase (NoSQL) | Open Source (Apache 2.0) |\n",
      "| **Hasura**   | Moderate                 | High                                       | Yes           | Yes (via plugins)    | Yes                | Yes                      | Yes            | Yes                    | PostgreSQL, MS SQL Server | Open Source (Apache 2.0) |\n",
      "| **Strapi**   | Easy                     | High                                       | Yes           | Yes (via plugins)    | Yes                | Yes                      | Yes            | Yes                    | SQL-based (PostgreSQL, MySQL, SQLite, etc.) | Open Source (MIT License) |\n",
      "\n",
      "### Key Points:\n",
      "1. **Ease of Self-Hosting:**\n",
      "   - **Easy:** Appwrite, Budibase, Directus, Parse, Strapi\n",
      "   - **Moderate:** Supabase, SurrealDB, Couchbase, Hasura\n",
      "\n",
      "2. **Feature Parity:**\n",
      "   - Most platforms offer high feature parity between self-hosted and cloud versions.\n",
      "\n",
      "3. **GUI/WebUI:**\n",
      "   - All platforms except SurrealDB offer a GUI or WebUI for management.\n",
      "\n",
      "4. **Full Text Search:**\n",
      "   - Supabase, Directus, SurrealDB, Hasura, and Strapi support full text search natively or via plugins.\n",
      "\n",
      "5. **Customer OAuth:**\n",
      "   - All platforms support customer OAuth, either natively or via plugins.\n",
      "\n",
      "6. **Granular Permissions:**\n",
      "   - All platforms support granular permissions.\n",
      "\n",
      "7. **API Access:**\n",
      "   - All platforms provide API access to the database.\n",
      "\n",
      "8. **Multi-Site Support:**\n",
      "   - Most platforms support multi-site, except for SurrealDB which is limited to a single instance.\n",
      "\n",
      "9. **Backend Flexibility:**\n",
      "   - **Generic Backends ... (truncated)\n",
      "\n",
      "<|Response B|>\n",
      "Below is a comparison table of the mentioned platforms based on your criteria: self-hosting ease, feature parity, backend migration ease, support for full-text search, GUI/WebUI availability, cost, and capability to host multiple sites with customer OAuth. Please note that the information provided is based on the general knowledge available as of early 2023 and might change as these platforms evolve.\n",
      "\n",
      "| Platform      | Self-Hosting Ease | Feature Parity with Cloud | Backend Migration Ease | Full-Text Search | GUI/WebUI | Cost        | Multi-Site Hosting | Customer OAuth |\n",
      "|---------------|-------------------|---------------------------|------------------------|------------------|-----------|-------------|--------------------|----------------|\n",
      "| Supabase      | High              | High                      | High                   | Yes              | Yes       | Open Source | Yes                | Yes            |\n",
      "| Appwrite      | High              | High                      | High                   | Yes              | Yes       | Open Source | Yes                | Yes            |\n",
      "| Budibase      | Medium            | Medium                    | High                   | Limited          | Yes       | Open Source | Yes                | Yes            |\n",
      "| Directus      | High              | High                      | High                   | Yes              | Yes       | Open Source | Yes                | Yes            |\n",
      "| SurrealDB     | Medium            | Medium                    | Medium                 | Yes              | Yes       | Open Source | Yes                | Yes            |\n",
      "| Parse         | Medium            | Medium                    | Medium                 | Limited          | Yes       | Open Source | Yes                | Yes            |\n",
      "| Couchbase     | Medium            | Medium                    | Low                    | Yes              | Yes       | Commercial  | Yes                | Yes            |\n",
      "\n",
      "### Detailed Comparison:\n",
      "\n",
      "- **Supabase**: \n",
      "  - Self-Hosting Ease: High. It's designed to be easy to deploy on your own infrastructure.\n",
      "  - Feature Parity: High. Self-hosted version offers most features available in the cloud version.\n",
      "  - Backend Migration Ease: High. Uses PostgreSQL, which is widely supported.\n",
      "  - Full-Text Search: Yes, via PostgreSQL.\n",
      "  - GUI/WebUI: Yes, provides a comprehensive web interface.\n",
      "  - Cost: Open Source.\n",
      "  - Multi-Site Hosting: Yes.\n",
      "  - Customer OAuth: Yes.\n",
      "\n",
      "- **Appwrite**:\n",
      "  - Self-Hosting Ease: High. Offers straightforward installation scripts.\n",
      "  - Feature Parity: High. Self-hosted version is quite feature-rich.\n",
      "  - Backend Migration Ease: High. Uses a standard database setup that can be migrated.\n",
      "  - Full-Text Search: Yes.\n",
      "  - GUI/WebUI: Yes, user-friendly interface.\n",
      "  - Cost: Open Source.\n",
      "  - Multi-Site Hosting: Yes.\n",
      "  - Customer OAuth: Yes.\n",
      "\n",
      "- **Budibase**:\n",
      "  - Self-Hosting Ease: Medium. Requires some configuration but is manageable.\n",
      "  - Feature Parity: Medium. Some features might be less polished in self-hosted.\n",
      "  - Backend Migration Ease: High. Uses SQLite or MongoDB, which are common.\n",
      "  - Full-Text Search: Limited.\n",
      "  - GUI/WebUI: Yes, good for building and managing apps.\n",
      "  - Cost: Open Source.\n",
      "  - Multi-Site Hosting: Yes.\n",
      "  - Customer OAuth: Yes.\n",
      "\n",
      "- **Directus**:\n",
      "  - Self-Hosting Ease: High. Very straightforward setup.\n",
      "  - Feature Parity: High. Self-hosted version is very close to the cloud version.\n",
      "  - Backend Migration Ease: High. Uses SQL databases.\n",
      "  - Full-Text Search: Yes.\n",
      "  - GUI/WebUI: Yes, extensive admin interface.\n",
      "  - Cost: Open Source.\n",
      "  - Multi-Site Hosting: Yes.\n",
      "  - Customer OAuth: Yes.\n",
      "\n",
      "- **SurrealDB**:\n",
      "  - Self-Hosting Ease: Medium. Newer platform, some complexities might arise.\n",
      "  - Feature Parity: Medium. Still evolving, so some features might be in development.\n",
      "  - Backend Migration Ease: Medium. Uses its own query language.\n",
      "  - Full-Text Search: Yes.\n",
      "  - GUI/WebUI: Yes.\n",
      "  - Cost: Open Source.\n",
      "  - Multi-Site Hosting: Yes.\n",
      "  - Customer OAuth: Yes.\n",
      "\n",
      "- **Parse**:\n",
      "  - Self-Hosting Ease: Medium. Requires ... (truncated)\n",
      "\n",
      "<|Which response do you prefer?|>\n",
      "<|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|>\n",
      "**label: 0\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print(tokenizer.decode(tokenized_dataset[\"ft48k_val\"][i][\"input_ids\"], skip_special_tokens=False))\n",
    "print(\"**label:\", tokenized_dataset[\"ft48k_val\"][i][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (3/3 shards): 100%|██████████| 135588/135588 [00:01<00:00, 112465.78 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 136/136 [00:00<00:00, 19768.00 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 47952/47952 [00:00<00:00, 133743.89 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 485/485 [00:00<00:00, 55947.12 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset.save_to_disk(\"/group-volume/binfeng/wsdm/data/tokenized_qwen14b_distill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
