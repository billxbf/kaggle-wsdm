{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "from huggingface_hub import login\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "tqdm.pandas()\n",
    "\n",
    "# Change the working directory to the directory containing the script\n",
    "os.chdir(\"/group-volume/binfeng/wsdm/stage_qft\")\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"google/gemma-2-9b-it\"\n",
    "MAX_LENGTH = 2000\n",
    "MAX_PROMPT_LENGTH = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/group-volume/binfeng/wsdm/tokenizer/gemma9b/tokenizer_config.json',\n",
       " '/group-volume/binfeng/wsdm/tokenizer/gemma9b/special_tokens_map.json',\n",
       " '/group-volume/binfeng/wsdm/tokenizer/gemma9b/tokenizer.model',\n",
       " '/group-volume/binfeng/wsdm/tokenizer/gemma9b/added_tokens.json',\n",
       " '/group-volume/binfeng/wsdm/tokenizer/gemma9b/tokenizer.json')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'right'\n",
    "tokenizer.save_pretrained(\"/group-volume/binfeng/wsdm/tokenizer/gemma9b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = pd.read_parquet(\"/group-volume/binfeng/wsdm/stage_qft/data/ft48k_calibrated.parquet\")\n",
    "ft.dropna(inplace=True)\n",
    "ft[\"text\"] = ft.apply(lambda x: format_text(tokenizer, x.prompt, x.response_a, x.response_b, \n",
    "                                                max_len=MAX_LENGTH, max_prompt_len=MAX_PROMPT_LENGTH), axis=1)\n",
    "ft[\"label\"] = ft.apply(lambda x: format_label(x.winner), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft = pd.read_parquet(\"/group-volume/binfeng/wsdm/stage_qft/data/soft87k.parquet\")\n",
    "soft.dropna(inplace=True)\n",
    "soft[\"text\"] = soft.apply(lambda x: format_text(tokenizer, x.prompt, x.response_a, x.response_b, \n",
    "                                                max_len=MAX_LENGTH, max_prompt_len=MAX_PROMPT_LENGTH), axis=1)\n",
    "soft[\"label\"] = soft.apply(lambda x: format_label(x.winner), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47226 1211\n",
      "85563 2194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.11/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=40.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=40, shuffle=True, random_state=66)\n",
    "for train_index, val_index in skf.split(ft, ft[\"language\"]):\n",
    "    ft_train, ft_val = ft.iloc[train_index], ft.iloc[val_index]\n",
    "    print(len(ft_train), len(ft_val))\n",
    "    break\n",
    "\n",
    "\n",
    "soft[\"logits_qwencd_cali\"] = soft[\"logits_qwencd\"]\n",
    "soft[\"logits_qwen32_cali\"] = soft[\"logits_qwen32\"]\n",
    "kf = KFold(n_splits=40, shuffle=True, random_state=66)\n",
    "for train_index, val_index in kf.split(soft):\n",
    "    soft_train, soft_val = soft.iloc[train_index], soft.iloc[val_index]\n",
    "    print(len(soft_train), len(soft_val))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 47226/47226 [00:24<00:00, 1913.19 examples/s]\n",
      "Map: 100%|██████████| 1211/1211 [00:00<00:00, 1590.01 examples/s]\n",
      "Map: 100%|██████████| 85563/85563 [00:43<00:00, 1952.27 examples/s]\n",
      "Map: 100%|██████████| 2194/2194 [00:00<00:00, 2325.00 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    ft_train: Dataset({\n",
       "        features: ['labels', 'logits_qwencd_cali', 'logits_qwen32_cali', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 47226\n",
       "    })\n",
       "    ft_val: Dataset({\n",
       "        features: ['labels', 'logits_qwencd_cali', 'logits_qwen32_cali', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1211\n",
       "    })\n",
       "    soft_train: Dataset({\n",
       "        features: ['labels', 'logits_qwencd_cali', 'logits_qwen32_cali', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 85563\n",
       "    })\n",
       "    soft_val: Dataset({\n",
       "        features: ['labels', 'logits_qwencd_cali', 'logits_qwen32_cali', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2194\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer_func(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"], \n",
    "        padding='max_length', \n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=True,\n",
    "        return_tensors='np'\n",
    "    )\n",
    "\n",
    "\n",
    "ft_train_dataset = Dataset.from_pandas(ft_train[[\"text\", \"label\", \"logits_qwencd_cali\", \"logits_qwen32_cali\"]])\n",
    "ft_val_dataset = Dataset.from_pandas(ft_val[[\"text\", \"label\", \"logits_qwencd_cali\", \"logits_qwen32_cali\"]])\n",
    "soft_train_dataset = Dataset.from_pandas(soft_train[[\"text\", \"label\", \"logits_qwencd_cali\", \"logits_qwen32_cali\"]])\n",
    "soft_val_dataset = Dataset.from_pandas(soft_val[[\"text\", \"label\", \"logits_qwencd_cali\", \"logits_qwen32_cali\"]])\n",
    "raw_dataset = DatasetDict({\n",
    "    'ft_train': ft_train_dataset,\n",
    "    'ft_val': ft_val_dataset,\n",
    "    'soft_train':soft_train_dataset,\n",
    "    'soft_val': soft_val_dataset\n",
    "})\n",
    "\n",
    "tokenized_dataset = raw_dataset.map(tokenizer_func, batched=True)\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
    "tokenized_dataset = tokenized_dataset.remove_columns(['__index_level_0__', 'text'])\n",
    "tokenized_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><|User Prompt|>\n",
      "<bos>Please write a small echo TCP server in Python.\n",
      "\n",
      "<|Response A|>\n",
      "<bos>Below is a simple **Echo TCP Server** implemented in Python. This server listens for incoming TCP connections, receives data from clients, and sends the same data back to them, effectively \"echoing\" the input.\n",
      "\n",
      "### Echo TCP Server in Python\n",
      "\n",
      "```python\n",
      "import socket\n",
      "import threading\n",
      "\n",
      "def handle_client(client_socket, client_address):\n",
      "    print(f\"[+] New connection from {client_address}\")\n",
      "    try:\n",
      "        while True:\n",
      "            # Receive data from the client (buffer size: 1024 bytes)\n",
      "            data = client_socket.recv(1024)\n",
      "            if not data:\n",
      "                # No data received, client has closed the connection\n",
      "                print(f\"[-] Connection closed by {client_address}\")\n",
      "                break\n",
      "            print(f\"[{client_address}] Received: {data.decode().strip()}\")\n",
      "            \n",
      "            # Echo the received data back to the client\n",
      "            client_socket.sendall(data)\n",
      "    except ConnectionResetError:\n",
      "        print(f\"[!] Connection reset by {client_address}\")\n",
      "    finally:\n",
      "        client_socket.close()\n",
      "        print(f\"[+] Connection with {client_address} closed.\\n\")\n",
      "\n",
      "def start_server(host='0.0.0.0', port=9999):\n",
      "    server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
      "    server.bind((host, port))\n",
      "    server.listen(5)\n",
      "    print(f\"[+] Echo server started on {host}:{port}\")\n",
      "    \n",
      "    try:\n",
      "        while True:\n",
      "            client_sock, client_addr = server.accept()\n",
      "            # Handle each client connection in a new thread\n",
      "            client_thread = threading.Thread(target=handle_client, args=(client_sock, client_addr))\n",
      "            client_thread.daemon = True\n",
      "            client_thread.start()\n",
      "    except KeyboardInterrupt:\n",
      "        print(\"\\n[!] Server shutting down.\")\n",
      "    finally:\n",
      "        server.close()\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    # You can change the host and port as needed\n",
      "    start_server(host='0.0.0.0', port=9999)\n",
      "```\n",
      "\n",
      "### How It Works\n",
      "\n",
      "1. **Importing Modules:**\n",
      "   - `socket`: Provides access to the BSD socket interface.\n",
      "   - `threading`: Allows the server to handle multiple clients concurrently.\n",
      "\n",
      "2. **Handling Clients (`handle_client` function):**\n",
      "   - **Connection Acknowledgment:** Prints a message when a new client connects.\n",
      "   - **Receiving Data:** The server waits to receive data from the client. It reads up to 1024 bytes at a time.\n",
      "   - **Echoing Data:** Sends the received data back to the client using `sendall()`, ensuring all data is sent.\n",
      "   - **Graceful Shutdown:** If the client closes the connection or an error occurs, the server cleans up by closing the socket and printing a disconnection message.\n",
      "\n",
      "3. **Starting the Server (`start_server` function):**\n",
      "   - **Creating a Socket:** Initializes a TCP socket.\n",
      "   - **Binding to Address and Port:** Binds the socket to the specified host and port. `'0.0.0.0'` means the server will listen on all available network interfaces.\n",
      "   - **Listening for Connections:** The `listen(5)` call tells the socket to start listening for incoming connections with a backlog of 5.\n",
      "   - **Accepting Connections:** The server enters an infinite loop, accepting incoming connections and spawning a new daemon thread for each client to handle the communication.\n",
      "\n",
      "4. **Running the Server:**\n",
      "   - The `if __name__ == \"__main__\":` block ensures that the server starts when the script is run directly.\n",
      "   - You can modify the `host` and `port` parameters to suit your network configuration and desired port.\n",
      "\n",
      "### Running the Server\n",
      "\n",
      "1. **Save the Script:**\n",
      "   - Save the above code in a file named `echo_server.py`.\n",
      "\n",
      "2. **Run the Server:**\n",
      "   ```bash\n",
      "   python echo_server.py\n",
      "   ```\n",
      "   - The server will start and listen on all available network interfaces at port `9999`.\n",
      "\n",
      "3. **Testing the Server:**\n",
      "   - You can test the echo server using `telnet` or `nc` (Netcat).\n",
      "   - **Using Telnet:**\n",
      "     ```bash\n",
      "     telnet localhost 9999\n",
      "     ```\n",
      "     - Type some text and press Enter. The server should echo the text back.\n",
      "   - **Using Netcat:**\n",
      "     ```bash\n",
      "     nc localhost 9999\n",
      "     ```\n",
      "     - Similarly, type text and press Enter to see it echoed back.\n",
      "\n",
      "4. **Stopping the Server:**\n",
      "   - Press `Ctrl+C` in the terminal where the server is running to stop the server gracefully.\n",
      "\n",
      "### Notes\n",
      "\n",
      "- **Concurrency:** The server uses threading to handle multiple clients simultaneously. For high-performance applications, consider using asynchronous I/O (e.g., `asyncio`) or multiprocessing.\n",
      "- **Security:** This is a basic echo server for educational purposes. For production use, consider implementing proper security measures, such as input validation, encryption (e.g., TLS), and access control.\n",
      "- **Error Handling:** The server includes basic error handling for connection resets and graceful shutdowns. Depending on your use case, you might want to ... (truncated 338 tokens)\n",
      "\n",
      "<|Response B|>\n",
      "<bos>Certainly! Below is a simple TCP echo server written in Python. This server listens for incoming connections, receives data from clients, and sends the same data back to them (hence the term \"echo\").\n",
      "\n",
      "```python\n",
      "import socket\n",
      "\n",
      "def start_echo_server(host='127.0.0.1', port=65432):\n",
      "    # Create a TCP/IP socket\n",
      "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as server_socket:\n",
      "        # Bind the socket to the address and port\n",
      "        server_socket.bind((host, port))\n",
      "        # Listen for incoming connections\n",
      "        server_socket.listen()\n",
      "        print(f\"Echo server started on {host}:{port}\")\n",
      "\n",
      "        while True:\n",
      "            # Wait for a connection\n",
      "            print(\"Waiting for a connection...\")\n",
      "            client_socket, client_address = server_socket.accept()\n",
      "            with client_socket:\n",
      "                print(f\"Connected by {client_address}\")\n",
      "                while True:\n",
      "                    # Receive data from the client\n",
      "                    data = client_socket.recv(1024)\n",
      "                    if not data:\n",
      "                        # No more data from client\n",
      "                        print(f\"Connection closed by {client_address}\")\n",
      "                        break\n",
      "                    # Send the data back to the client\n",
      "                    client_socket.sendall(data)\n",
      "                    print(f\"Echoed: {data.decode()}\")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    start_echo_server()\n",
      "```\n",
      "\n",
      "### How It Works:\n",
      "1. **Socket Creation**: The server creates a TCP socket using `socket.socket(socket.AF_INET, socket.SOCK_STREAM)`.\n",
      "2. **Binding**: The server binds the socket to a specific address and port using `bind()`.\n",
      "3. **Listening**: The server listens for incoming connections with `listen()`.\n",
      "4. **Accepting Connections**: The server enters a loop where it waits for client connections using `accept()`. When a client connects, it returns a new socket object representing the connection and the address of the client.\n",
      "5. **Receiving and Sending Data**: The server receives data from the client using `recv()` and sends the same data back using `sendall()`.\n",
      "6. **Connection Closure**: The server continues to echo data until the client closes the connection. When the client closes the connection, the server closes the socket and waits for the next connection.\n",
      "\n",
      "### Running the Server:\n",
      "1. Save the code to a file, e.g., `echo_server.py`.\n",
      "2. Run the server using Python:\n",
      "   ```bash\n",
      "   python echo_server.py\n",
      "   ```\n",
      "3. The server will start and listen on `127.0.0.1:65432`.\n",
      "\n",
      "### Testing the Server:\n",
      "You can test the server using a simple TCP client, such as `telnet` or `netcat`:\n",
      "\n",
      "```bash\n",
      "telnet 127.0.0.1 65432\n",
      "```\n",
      "\n",
      "Or using `netcat`:\n",
      "\n",
      "```bash\n",
      "nc 127.0.0.1 65432\n",
      "```\n",
      "\n",
      "Type some text, and the server will echo it back to you.\n",
      "\n",
      "### Notes:\n",
      "- The server handles one client at a time. For handling multiple clients simultaneously, you would need to use threading or asynchronous I/O.\n",
      "- The server runs indefinitely until manually stopped (e.g., by pressing `Ctrl+C`).\n",
      "\n",
      "<|Which response do you prefer?|>\n",
      "<eos><eos><eos><eos><eos><eos><eos><eos><eos>\n",
      "**label: 0\n"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "print(tokenizer.decode(tokenized_dataset[\"soft_val\"][i][\"input_ids\"], skip_special_tokens=False))\n",
    "print(\"**label:\", tokenized_dataset[\"soft_val\"][i][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 47226/47226 [00:00<00:00, 222681.83 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 47226/47226 [00:00<00:00, 149622.43 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1211/1211 [00:00<00:00, 92372.78 examples/s]\n",
      "Saving the dataset (2/2 shards): 100%|██████████| 85563/85563 [00:00<00:00, 115858.71 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 2194/2194 [00:00<00:00, 101858.49 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset.save_to_disk(\"/group-volume/binfeng/wsdm/stage_qft/dataset/tokenized_gemma9b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
